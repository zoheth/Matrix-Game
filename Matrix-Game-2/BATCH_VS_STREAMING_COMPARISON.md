# Batch vs Streaming æ¨ç†å¯¹æ¯”

## ğŸ“Œ æ ¸å¿ƒç»“è®º

**æ˜¯çš„ï¼Œæ¨ç†æ ¸å¿ƒå‡ ä¹å®Œå…¨ä¸€æ ·ï¼** ä¸»è¦åŒºåˆ«åœ¨äºï¼š

1. âœ… **æ¨ç†ç®—æ³•ï¼š** å®Œå…¨ç›¸åŒï¼ˆDiffusion å»å™ª + KV Cache + VAE è§£ç ï¼‰
2. âŒ **æ¡ä»¶è·å–ï¼š** Batch æ˜¯é™æ€é¢„è®¾ï¼ŒStreaming æ˜¯åŠ¨æ€äº¤äº’
3. âŒ **è¾“å‡ºæ—¶æœºï¼š** Batch æœ€åè¾“å‡ºï¼ŒStreaming æ¯å—å®æ—¶è¾“å‡º
4. âŒ **ç”¨æˆ·äº¤äº’ï¼š** Batch æ— äº¤äº’ï¼ŒStreaming æ¯å—å¯æ§åˆ¶/åœæ­¢

---

## ğŸ” é€è¡Œå¯¹æ¯”æ ¸å¿ƒå·®å¼‚

### **å·®å¼‚ 1: æ¡ä»¶å‡†å¤‡æ–¹å¼**

#### Batch æ¨¡å¼ ([inference.py](inference.py)):
```python
# ä¸€æ¬¡æ€§ç”Ÿæˆæ‰€æœ‰åŠ¨ä½œæ¡ä»¶
if mode == 'universal':
    cond_data = Bench_actions_universal(num_frames)  # â† é¢„ç”Ÿæˆ 597 å¸§åŠ¨ä½œ
    mouse_condition = cond_data['mouse_condition'].unsqueeze(0)
    conditional_dict['mouse_cond'] = mouse_condition

keyboard_condition = cond_data['keyboard_condition'].unsqueeze(0)
conditional_dict['keyboard_cond'] = keyboard_condition

# æ‰€æœ‰ block å…±ç”¨åŒä¸€ä¸ª conditional_dict
for block in range(50):
    self.generator(..., conditional_dict=cond_current(conditional_dict, ...))
```

#### Streaming æ¨¡å¼ ([pipeline/causal_inference.py:593](pipeline/causal_inference.py#L593)):
```python
# åˆå§‹åŒ–æ—¶ä¹Ÿæ˜¯é¢„ç”Ÿæˆï¼ˆä½œä¸ºé»˜è®¤å€¼ï¼‰
cond_data = Bench_actions_universal(num_frames)
conditional_dict['mouse_cond'] = ...
conditional_dict['keyboard_cond'] = ...

# ä½†æ¯ä¸ª block å‰ä¼šåŠ¨æ€æ›¿æ¢ï¼
for block in range(max_blocks):
    current_actions = get_current_action(mode=mode)  # ğŸ® å®æ—¶ç”¨æˆ·è¾“å…¥
    new_act, conditional_dict = cond_current(
        conditional_dict,
        current_start_frame,
        num_frame_per_block,
        replace=current_actions,  # â† å…³é”®ï¼šåŠ¨æ€æ›¿æ¢å½“å‰å—çš„æ¡ä»¶
        mode=mode
    )
    self.generator(..., conditional_dict=new_act)  # ä½¿ç”¨æ›´æ–°åçš„æ¡ä»¶
```

**å…³é”®å‡½æ•° `cond_current` çš„å·®å¼‚ï¼š**

| å‚æ•° | Batch æ¨¡å¼ | Streaming æ¨¡å¼ |
|------|-----------|---------------|
| `replace` | `None` | `current_actions` (ç”¨æˆ·è¾“å…¥) |
| è¡Œä¸º | åªåˆ‡ç‰‡ï¼Œä¸ä¿®æ”¹ | åˆ‡ç‰‡ + æ›¿æ¢æŒ‡å®šåŒºé—´ |

---

### **å·®å¼‚ 2: æ¯å—å®Œæˆåçš„å¤„ç†**

#### Batch æ¨¡å¼ ([pipeline/causal_inference.py:352-362](pipeline/causal_inference.py#L352-L362)):
```python
# å»å™ªå®Œæˆ
denoised_pred = ...

# æ›´æ–° KV Cache
self.generator(denoised_pred, ..., timestep=context_noise)

# VAE è§£ç 
with torch.profiler.record_function(f"2.3.{block_idx}_VAE_Decode"):
    denoised_pred = denoised_pred.transpose(1,2)
    video, vae_cache = self.vae_decoder(denoised_pred.half(), *vae_cache)
    videos += [video]  # â† åªæ˜¯åŠ å…¥åˆ—è¡¨

current_start_frame += current_num_frames
# âŒ æ²¡æœ‰ä¿å­˜è§†é¢‘
# âŒ æ²¡æœ‰ç”¨æˆ·äº¤äº’
# ç›´æ¥è¿›å…¥ä¸‹ä¸€ä¸ª block
```

#### Streaming æ¨¡å¼ ([pipeline/causal_inference.py:654-673](pipeline/causal_inference.py#L654-L673)):
```python
# å»å™ªå®Œæˆ
denoised_pred = ...

# æ›´æ–° KV Cache
self.generator(denoised_pred, ..., timestep=context_noise)

# VAE è§£ç 
denoised_pred = denoised_pred.transpose(1,2)
video, vae_cache = self.vae_decoder(denoised_pred.half(), *vae_cache)
videos += [video]

# âœ… ç«‹å³è½¬æ¢ä¸ºè§†é¢‘æ ¼å¼
video = rearrange(video, "B T C H W -> B T H W C")
video = ((video.float() + 1) * 127.5).clip(0, 255).cpu().numpy().astype(np.uint8)[0]
video = np.ascontiguousarray(video)

# âœ… å‡†å¤‡å¯è§†åŒ–é…ç½®
if mode != 'templerun':
    config = (
        conditional_dict["keyboard_cond"][...].float().cpu().numpy(),
        conditional_dict["mouse_cond"][...].float().cpu().numpy()
    )

# âœ… å®æ—¶ä¿å­˜å½“å‰è¿›åº¦
mouse_icon = 'assets/images/mouse.png'
process_video(
    video.astype(np.uint8),
    output_folder + f'/{name}_current.mp4',  # â† æ¯å—éƒ½è¦†ç›–ä¿å­˜
    config, mouse_icon,
    mouse_scale=0.1,
    process_icon=False,
    mode=mode
)

current_start_frame += current_num_frames

# âœ… ç”¨æˆ·äº¤äº’ï¼šè¯¢é—®æ˜¯å¦ç»§ç»­
if input("Continue? (Press `n` to break)").strip() == "n":
    break  # å¯ä»¥æå‰ç»ˆæ­¢
```

---

### **å·®å¼‚ 3: æœ€ç»ˆè¾“å‡º**

#### Batch æ¨¡å¼ ([inference.py:185-203](inference.py#L185-L203)):
```python
# æ‰€æœ‰ block å®Œæˆåï¼Œä¸€æ¬¡æ€§å¤„ç†
with torch.profiler.record_function("3_Video_Postprocessing"):
    videos_tensor = torch.cat(videos, dim=1)  # æ‹¼æ¥æ‰€æœ‰ block
    videos = rearrange(videos_tensor, "B T C H W -> B T H W C")
    videos = ((videos.float() + 1) * 127.5).clip(0, 255).cpu().numpy().astype(np.uint8)[0]
    video = np.ascontiguousarray(videos)
    # å‡†å¤‡é…ç½®...

# æœ€åä¿å­˜ä¸¤ä¸ªç‰ˆæœ¬
with torch.profiler.record_function("4_Video_Export"):
    process_video(..., 'demo.mp4', ...)         # æ— å›¾æ ‡ç‰ˆæœ¬
    process_video(..., 'demo_icon.mp4', ...)    # å¸¦å›¾æ ‡ç‰ˆæœ¬
```

#### Streaming æ¨¡å¼ ([pipeline/causal_inference.py:676-690](pipeline/causal_inference.py#L676-L690)):
```python
# å¾ªç¯ç»“æŸåï¼ˆç”¨æˆ·åœæ­¢æˆ–è¾¾åˆ°ä¸Šé™ï¼‰
videos_tensor = torch.cat(videos, dim=1)
videos = rearrange(videos_tensor, "B T C H W -> B T H W C")
videos = ((videos.float() + 1) * 127.5).clip(0, 255).cpu().numpy().astype(np.uint8)[0]
video = np.ascontiguousarray(videos)

# ä¿å­˜å®Œæ•´è§†é¢‘ï¼ˆå¸¦/ä¸å¸¦å›¾æ ‡ï¼‰
process_video(..., output_folder + f'/{name}.mp4', ...)       # æ— å›¾æ ‡
process_video(..., output_folder + f'/{name}_icon.mp4', ...)  # å¸¦å›¾æ ‡

# æ³¨æ„ï¼šæ­¤æ—¶ {name}_current.mp4 å·²ç»å­˜åœ¨ï¼ˆæœ€åä¸€ä¸ª block çš„ç‰ˆæœ¬ï¼‰
```

---

### **å·®å¼‚ 4: Profiling æ”¯æŒ**

#### Batch æ¨¡å¼:
```python
def inference(self, ..., profile=False):
    if profile:
        diffusion_start = torch.cuda.Event(enable_timing=True)
        diffusion_end = torch.cuda.Event(enable_timing=True)

    for block_idx, current_num_frames in enumerate(tqdm(all_num_frames)):
        if profile:
            torch.cuda.synchronize()
            diffusion_start.record()

        # ... æ¨ç†è¿‡ç¨‹ ...

        if profile:
            torch.cuda.synchronize()
            diffusion_end.record()
            diffusion_time = diffusion_start.elapsed_time(diffusion_end)
            print(f"diffusion_time: {diffusion_time}", flush=True)
            fps = video.shape[1] * 1000 / diffusion_time
            print(f"  - FPS: {fps:.2f}")
```

#### Streaming æ¨¡å¼:
```python
def inference(self, ...):
    # âŒ æ²¡æœ‰ profile å‚æ•°
    # âŒ æ²¡æœ‰ CUDA Events è®¡æ—¶
    # ä¸“æ³¨äºäº¤äº’æ€§ï¼Œä¸å…³å¿ƒæ€§èƒ½åˆ†æ
```

---

## ğŸ“Š å®Œæ•´å¯¹æ¯”è¡¨

| ç‰¹æ€§ | **CausalInferencePipeline** (Batch) | **CausalInferenceStreamingPipeline** |
|------|-------------------------------------|-------------------------------------|
| **ç±»å** | `CausalInferencePipeline` | `CausalInferenceStreamingPipeline` |
| **æ–‡ä»¶ä½ç½®** | [pipeline/causal_inference.py:134](pipeline/causal_inference.py#L134) | [pipeline/causal_inference.py:434](pipeline/causal_inference.py#L434) |
| **æ¨ç†ç®—æ³•** | âœ… å®Œå…¨ç›¸åŒ | âœ… å®Œå…¨ç›¸åŒ |
| **KV Cache** | âœ… å®Œå…¨ç›¸åŒ | âœ… å®Œå…¨ç›¸åŒ |
| **å»å™ªæ­¥éª¤** | âœ… å®Œå…¨ç›¸åŒ | âœ… å®Œå…¨ç›¸åŒ |
| **VAE è§£ç ** | âœ… å®Œå…¨ç›¸åŒ | âœ… å®Œå…¨ç›¸åŒ |
| | | |
| **æ¡ä»¶è·å–** | é¢„è®¾é™æ€åŠ¨ä½œ | ğŸ® æ¯å—å®æ—¶è¾“å…¥ |
| **æ¡ä»¶æ›´æ–°** | ä¸æ›´æ–° | `replace=current_actions` |
| **å®æ—¶è¾“å‡º** | âŒ æ—  | âœ… æ¯å—ä¿å­˜ `_current.mp4` |
| **ç”¨æˆ·äº¤äº’** | âŒ æ—  | âœ… æ¯å—è¯¢é—®æ˜¯å¦ç»§ç»­ |
| **æå‰ç»ˆæ­¢** | âŒ ä¸æ”¯æŒ | âœ… æŒ‰ 'n' åœæ­¢ |
| **Profiling** | âœ… æ”¯æŒ CUDA Events | âŒ ä¸æ”¯æŒ |
| **è¿›åº¦æ¡** | âœ… tqdm | âŒ æ—  |
| | | |
| **è¾“å‡ºæ–‡ä»¶** | `demo.mp4`, `demo_icon.mp4` | `{name}.mp4`, `{name}_icon.mp4`, `{name}_current.mp4` |
| **é€‚ç”¨åœºæ™¯** | ç¦»çº¿æ¸²æŸ“ã€æ€§èƒ½æµ‹è¯• | äº¤äº’å¼ Demoã€å®æ—¶æ¸¸æˆ |

---

## ğŸ§ª ä»£ç å¤ç”¨æƒ…å†µ

### **å…±äº«éƒ¨åˆ†ï¼ˆ100% ç›¸åŒï¼‰ï¼š**

1. âœ… `_initialize_kv_cache()` - KV Cache åˆå§‹åŒ–
2. âœ… `_initialize_kv_cache_mouse_and_keyboard()` - åŠ¨ä½œæ¡ä»¶ Cache
3. âœ… `_initialize_crossattn_cache()` - äº¤å‰æ³¨æ„åŠ› Cache
4. âœ… Diffusion å»å™ªå¾ªç¯é€»è¾‘
5. âœ… Scheduler æ·»åŠ å™ªå£°
6. âœ… VAE Decoder è°ƒç”¨

### **ç‹¬æœ‰éƒ¨åˆ†ï¼š**

#### Batch æ¨¡å¼ç‹¬æœ‰ï¼š
- âœ… `profile` å‚æ•°å’Œ CUDA Events è®¡æ—¶
- âœ… tqdm è¿›åº¦æ¡
- âœ… torch.profiler.record_function æ ‡ç­¾ï¼ˆæˆ‘ä»¬æ·»åŠ çš„ï¼‰

#### Streaming æ¨¡å¼ç‹¬æœ‰ï¼š
- âœ… `get_current_action()` ç”¨æˆ·è¾“å…¥
- âœ… `cond_current(..., replace=current_actions)` æ¡ä»¶æ›¿æ¢
- âœ… æ¯å—åçš„è§†é¢‘ä¿å­˜
- âœ… æ¯å—åçš„ç”¨æˆ·äº¤äº’è¯¢é—®
- âœ… `output_folder` å’Œ `name` å‚æ•°

---

## ğŸ¯ å…³é”®å·®å¼‚æ€»ç»“

### **1. æ¡ä»¶æ§åˆ¶æ–¹å¼**

```python
# Batch: é™æ€æ¡ä»¶
conditional_dict = {...}  # å›ºå®šä¸å˜
for block in blocks:
    generator(..., conditional_dict=cond_current(conditional_dict, block, 3))
    # â†‘ cond_current åªæ˜¯åˆ‡ç‰‡ï¼Œä¸ä¿®æ”¹

# Streaming: åŠ¨æ€æ¡ä»¶
conditional_dict = {...}  # åˆå§‹åŒ–
for block in blocks:
    user_input = get_current_action()  # ğŸ® å®æ—¶è¾“å…¥
    new_cond, conditional_dict = cond_current(
        conditional_dict, block, 3,
        replace=user_input  # â† ä¿®æ”¹ conditional_dict
    )
    generator(..., conditional_dict=new_cond)
```

### **2. è¾“å‡ºæ—¶æœº**

```python
# Batch: æœ€åè¾“å‡º
for block in blocks:
    video = process_block()
    videos.append(video)  # åªå­˜å‚¨
final_video = concat(videos)
save_video(final_video)  # â† ä¸€æ¬¡æ€§ä¿å­˜

# Streaming: å®æ—¶è¾“å‡º
for block in blocks:
    video = process_block()
    videos.append(video)
    save_video(video, "current.mp4")  # â† æ¯æ¬¡éƒ½ä¿å­˜å½“å‰è¿›åº¦
    if user_says_stop():
        break
final_video = concat(videos)
save_video(final_video)  # â† å†ä¿å­˜å®Œæ•´ç‰ˆæœ¬
```

### **3. äº¤äº’æ€§**

```python
# Batch: æ— äº¤äº’
for block in blocks:
    process_block()
    # è‡ªåŠ¨è¿›å…¥ä¸‹ä¸€å—

# Streaming: æœ‰äº¤äº’
for block in blocks:
    process_block()
    if input("Continue?") == 'n':
        break  # ç”¨æˆ·å¯éšæ—¶åœæ­¢
```

---

## ğŸ’¡ è®¾è®¡æ€æƒ³

ä¸¤ä¸ª Pipeline çš„è®¾è®¡ä½“ç°äº†ï¼š

1. **ä»£ç å¤ç”¨ï¼š** æ ¸å¿ƒæ¨ç†é€»è¾‘å®Œå…¨ä¸€è‡´ï¼Œé¿å…é‡å¤
2. **èŒè´£åˆ†ç¦»ï¼š** Batch å…³æ³¨æ€§èƒ½å’Œå®Œæ•´æ€§ï¼ŒStreaming å…³æ³¨äº¤äº’æ€§
3. **çµæ´»æ‰©å±•ï¼š** é€šè¿‡ `replace` å‚æ•°ä¼˜é›…åœ°æ”¯æŒåŠ¨æ€æ¡ä»¶

### **ä¸ºä»€ä¹ˆä¸åˆå¹¶æˆä¸€ä¸ªç±»ï¼Ÿ**

è™½ç„¶é€»è¾‘ç›¸ä¼¼ï¼Œä½†åˆ†å¼€æœ‰å¥½å¤„ï¼š
- âœ… Batch å¯ä»¥ä¸“æ³¨ä¼˜åŒ–æ€§èƒ½ï¼ˆprofiling, batchingï¼‰
- âœ… Streaming å¯ä»¥ä¸“æ³¨ç”¨æˆ·ä½“éªŒï¼ˆå®æ—¶åé¦ˆï¼‰
- âœ… é¿å…"ç‘å£«å†›åˆ€"ç±»ï¼ˆä¸€ä¸ªç±»åšå¤ªå¤šäº‹ï¼‰
- âœ… ç”¨æˆ·æ ¹æ®åœºæ™¯é€‰æ‹©åˆé€‚çš„å·¥å…·

---

## ğŸ”¬ éªŒè¯å®éªŒ

### **éªŒè¯æ¡ä»¶æ›¿æ¢ï¼š**

åœ¨ `cond_current` å‡½æ•°ä¸­æ·»åŠ æ‰“å°ï¼š

```python
def cond_current(conditional_dict, current_start_frame, num_frame_per_block, replace=None, mode='universal'):
    if replace != None:
        print(f"ğŸ® Replacing conditions for block {current_start_frame // num_frame_per_block}")
        print(f"  Keyboard: {replace['keyboard']}")
        if mode != 'templerun':
            print(f"  Mouse: {replace['mouse']}")
    # ...
```

**é¢„æœŸè¾“å‡ºï¼ˆStreamingï¼‰ï¼š**
```
ğŸ® Replacing conditions for block 0
  Keyboard: tensor([1, 0, 0, 0])  # Wé”®
  Mouse: tensor([0, 0.1])         # å³è½¬
...
```

**é¢„æœŸè¾“å‡ºï¼ˆBatchï¼‰ï¼š**
```
# æ— è¾“å‡ºï¼ˆreplace=Noneï¼‰
```

---

## ğŸ“ æ€»ç»“

ä½ çš„è§‚å¯Ÿæ˜¯æ­£ç¡®çš„ï¼ä¸¤ä¸ª Pipeline çš„æ¨ç†æ ¸å¿ƒ**å‡ ä¹ä¸€æ¨¡ä¸€æ ·**ï¼Œä¸»è¦åŒºåˆ«åœ¨äºï¼š

| æ–¹é¢ | åŒºåˆ«ç¨‹åº¦ |
|------|---------|
| **æ¨ç†ç®—æ³•** | 0% - å®Œå…¨ç›¸åŒ |
| **æ¡ä»¶è·å–** | 100% - å®Œå…¨ä¸åŒ |
| **è¾“å‡ºæ—¶æœº** | 100% - å®Œå…¨ä¸åŒ |
| **ç”¨æˆ·äº¤äº’** | 100% - å®Œå…¨ä¸åŒ |
| **ä»£ç ç»“æ„** | ~10% - å¾®å°å·®å¼‚ |

æ ¸å¿ƒæ¨ç†æµç¨‹å¯ä»¥ç”¨åŒä¸€å¼ æµç¨‹å›¾è¡¨ç¤ºï¼Œå·®å¼‚åªåœ¨**è¾“å…¥æ¥æº**å’Œ**è¾“å‡ºæ—¶æœº**ä¸¤ä¸ªå¤–å›´ç¯èŠ‚ã€‚
